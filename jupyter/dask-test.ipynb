{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97287ff0-4f34-435d-9f5b-515b3c8c5d1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testing Memory Usage of Dask\n",
    "\n",
    "## ESGF Data\n",
    "\n",
    "* http://esgf3.dkrz.de/thredds/fileServer/cmip6/CMIP/MPI-M/MPI-ESM1-2-HR/historical/r1i1p1f1/day/tas/gn/v20190710/tas_day_MPI-ESM1-2-HR_historical_r1i1p1f1_gn_19000101-19041231.nc\n",
    "\n",
    "## xarray\n",
    "\n",
    "* http://xarray.pydata.org/en/stable/user-guide/dask.html\n",
    "* http://stephanhoyer.com/2015/06/11/xray-dask-out-of-core-labeled-arrays/\n",
    "\n",
    "## Dask\n",
    "\n",
    "* https://blog.dask.org/2021/03/11/dask_memory_usage\n",
    "* https://docs.dask.org/en/latest/array-chunks.html\n",
    "* https://docs.dask.org/en/latest/dataframe-best-practices.html#repartition-to-reduce-overhead\n",
    "* https://coiled.io/tackling-unmanaged-memory-with-dask/\n",
    "* https://docs.dask.org/en/latest/diagnostics-distributed.html\n",
    "\n",
    "## Bugs\n",
    "\n",
    "* https://github.com/pydata/xarray/issues/3781\n",
    "* https://github.com/pydata/xarray/issues/3401\n",
    "\n",
    "## Memory profiler\n",
    "\n",
    "* https://pypi.org/project/dask_memusage/\n",
    "* https://pypi.org/project/filprofiler/\n",
    "    * https://pythonspeed.com/products/filmemoryprofiler/#profiling-in-jupyter\n",
    "* https://pypi.org/project/memory-profiler/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60815254-ed76-4f38-b384-1701e5f9537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import humanize\n",
    "import math\n",
    "import xarray as xr\n",
    "import dask\n",
    "\n",
    "from bokeh.plotting import show\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30318470-af04-4e7f-b278-4e41180c087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/how-to-get-current-cpu-and-ram-usage-in-python/\n",
    "import psutil\n",
    "\n",
    "print(f\"CPUs: {os.cpu_count()}\")\n",
    "print(f\"Total Memory: {humanize.naturalsize(psutil.virtual_memory()[0])}\")\n",
    "print(f\"Available Memory: {humanize.naturalsize(psutil.virtual_memory()[1])}\")\n",
    "print(f\"Used Memory: {humanize.naturalsize(psutil.virtual_memory()[3])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a5de3-bb7c-42a2-ae07-b0e38fb47c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.dask.org/en/latest/array-best-practices.html#avoid-oversubscribing-threads\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12702be-d5a8-41e7-9d49-e91e6714b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://xarray.pydata.org/en/stable/user-guide/dask.html#\n",
    "ds = xr.open_dataset(\n",
    "    # \"data/tas_day_MPI-ESM1-2-HR_historical_r1i1p1f1_gn_19000101-19041231.nc\",\n",
    "    \"data/ta_day_MPI-ESM1-2-HR_historical_r1i1p1f1_gn_19050101-19091231.nc\",\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad04a92-60d4-4de0-9e8b-aad043da8e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds.ta.sel(time='1905').squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442d19f-88e4-44fd-9bc3-a606857c8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/roocs/clisops/blob/1280f278b5017d1e1d8c938b95b1dc25508398b1/clisops/utils/output_utils.py#L167\n",
    "\n",
    "def get_chunk_length(da, mem_limit):\n",
    "    \"\"\"\n",
    "    Calculate the chunk length to use when chunking xarray datasets.\n",
    "    Based on memory limit provided in config and the size of th dataset.\n",
    "    \"\"\"\n",
    "    size = da.nbytes\n",
    "    n_times = len(da.time.values)\n",
    "    # mem_limit = parse_size(chunk_memory_limit)\n",
    "\n",
    "    if size > 0:\n",
    "        n_chunks = math.ceil(size / mem_limit)\n",
    "    else:\n",
    "        n_chunks = 1\n",
    "        \n",
    "    print(f\"num chunks: {n_chunks}\")\n",
    "\n",
    "    chunk_length = math.ceil(n_times / n_chunks)\n",
    "\n",
    "    return chunk_length\n",
    "\n",
    "def chunk(da, mem_limit):\n",
    "    # https://docs.dask.org/en/latest/array-best-practices.html#select-a-good-chunk-size\n",
    "    # dask.config.set({\"array.chunk-size\": chunk_memory_limit})\n",
    "    chunk_length = get_chunk_length(da, mem_limit)\n",
    "    print(f\"chunk length: {chunk_length}\")\n",
    "    da = da.chunk({\n",
    "        # \"time\": \"auto\"\n",
    "        \"time\": chunk_length\n",
    "    })\n",
    "    da = da.unify_chunks()\n",
    "    print(f\"chunks: {da.chunks}\")\n",
    "    return da\n",
    "\n",
    "def chunk_size(max_workers=None, max_memory=None):\n",
    "    max_workers = max_workers or os.cpu_count()\n",
    "    print(f\"max workers: {max_workers}\")\n",
    "    max_memory = max_memory or psutil.virtual_memory()[0]\n",
    "    print(f\"max memory: {humanize.naturalsize(max_memory, binary=True)}\")\n",
    "    max_chunks = 2\n",
    "    base_mem = 400 * 1024**2\n",
    "    max_threads = max_workers * max_chunks\n",
    "    chunk_size_ = int((max_memory - max_workers * base_mem) / max_threads)\n",
    "    print(f\"chunk size: {humanize.naturalsize(chunk_size_, binary=True)}\")\n",
    "    max_memory_per_worker = chunk_size_ * max_chunks + base_mem\n",
    "    print(f\"max memory per worker: {humanize.naturalsize(max_memory_per_worker, binary=True)}\")\n",
    "    return chunk_size_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f83b5-02f7-45e6-9250-e16350b79f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.dask.org/en/latest/caching.html?highlight=cache\n",
    "#from dask.cache import Cache\n",
    "#cache = Cache(2e9)  # Leverage two gigabytes of memory\n",
    "#cache.register()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09b17d-8064-4b04-987e-8b7bf5929550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.dask.org/en/latest/diagnostics-local.html\n",
    "from dask.diagnostics import ProgressBar, Profiler, ResourceProfiler, CacheProfiler\n",
    "from cachey import nbytes\n",
    "from dask.diagnostics import visualize\n",
    "\n",
    "# https://docs.dask.org/en/latest/setup/single-machine.html\n",
    "# https://docs.dask.org/en/latest/scheduling.html\n",
    "dask.config.set({\n",
    "    \"scheduler\": \"synchronous\", \n",
    "    # \"scheduler\": \"threads\", \n",
    "    # \"scheduler\": \"processes\", \n",
    "    # \"array.chunk-size\": chunk_size(),\n",
    "})\n",
    "da = chunk(da, chunk_size(max_workers=2, max_memory=1000*1024**2))\n",
    "with ProgressBar(), Profiler() as prof, ResourceProfiler() as rprof, CacheProfiler(metric=nbytes) as cprof:\n",
    "    da.to_netcdf(\"out.nc\", compute=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7842be-9ba2-4c62-a781-4535b800481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(visualize([prof, rprof, cprof]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
